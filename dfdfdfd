tmp_loss가 Generator 옛날걸로 <- discriminator 문젠가 확인 < x1이까맣게나온다..           ------->generator 이전껄로
test_net이 contextual attention 다음 넷만 옛날꺼 <- contextual attention이 문젠가 <ㄸㄱㅇ          ---->Discriminator 이전껄로

bash run_train.sh
Namespace(activation='elu', b1=0.5, b2=0.999, baseroot='/home/dataset/places2/small_image/data_256', batch_size=32, bbox_shape=30, checkpoint_interval=1, cudnn_benchmark=True, epochs=2, gan_type='WGAN', gpu_ids='1', imgsize=256, in_channels=4, init_gain=0.02, init_type='kaiming', lambda_gan=1.0, lambda_l1=10.0, lambda_perceptual=10.0, latent_channels=48, load_name='', logs_dir_path='/home/eh1404/works/DeepFillv2_Pytorch/models/ml_log', lr_d=0.0001, lr_decrease_epoch=10, lr_decrease_factor=0.5, lr_g=0.0001, margin=10, mask_num=20, mask_type='free_form', max_angle=4, max_len=20, max_width=5, meta_lr=0.0002, multi_gpu=True, norm='none', num_workers=6, out_channels=3, pad_type='zero', perceptual_loss=False, resume=True, resume_epoch=1, sample_path='./samples', save_path='./models/without_perceptual', update_lr=0.0002, update_step=3, weight_decay=0)
refine_conv_start: 68
Generator is created!
Initialize generator with kaiming type
Discriminator is created!
Initialize discriminator with kaiming type
--------------------Pretrained Models are Loaded--------------------
The overall number of images equals to 1803460
-----------------------------
-network each model rs shape-
/home/eh1404/anaconda3/envs/pt1/lib/python3.7/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
/home/eh1404/anaconda3/envs/pt1/lib/python3.7/site-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.
  warnings.warn("nn.functional.tanh is deprecated. Use torch.tanh instead.")
x1 torch.Size([32, 3, 160, 160])
x1  torch.Size([32, 4, 160, 160]) <<< mask 추가됨
finenet encoder  torch.Size([32, 192, 40, 40])
refine atten rs 1  torch.Size([32, 192, 40, 40])
after contextual attention  torch.Size([32, 192, 40, 40])
offset flow  torch.Size([32, 3, 160, 160])
refine atten rs 2 torch.Size([32, 192, 40, 40])
second out  torch.Size([32, 3, 160, 160])
final result  torch.Size([32, 3, 160, 160])
-----------------------------
[Epoch 2/2] [Batch 0/56358] [first Mask L1 Loss: 0.11720] [second Mask L1 Loss: 0.11694]
[D Loss: 1.00197] [G Loss: -0.06601] time_left: 3 days, 19:54:51.808605
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 160, 160])
x1  torch.Size([32, 4, 160, 160])
finenet encoder  torch.Size([32, 192, 40, 40])
refine atten rs 1  torch.Size([32, 192, 40, 40])
after contextual attention  torch.Size([32, 192, 40, 40])
offset flow  torch.Size([32, 3, 160, 160])
refine atten rs 2 torch.Size([32, 192, 40, 40])
second out  torch.Size([32, 3, 160, 160])
final result  torch.Size([32, 3, 160, 160])
-----------------------------
[Epoch 2/2] [Batch 1/56358] [first Mask L1 Loss: 0.11484] [second Mask L1 Loss: 0.11498]
[D Loss: 0.99680] [G Loss: -0.06668] time_left: 16:10:37.069769
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 160, 160])
x1  torch.Size([32, 4, 160, 160])
finenet encoder  torch.Size([32, 192, 40, 40])
refine atten rs 1  torch.Size([32, 192, 40, 40])
after contextual attention  torch.Size([32, 192, 40, 40])
offset flow  torch.Size([32, 3, 160, 160])
refine atten rs 2 torch.Size([32, 192, 40, 40])
second out  torch.Size([32, 3, 160, 160])
final result  torch.Size([32, 3, 160, 160])
-----------------------------
[Epoch 2/2] [Batch 2/56358] [first Mask L1 Loss: 0.10941] [second Mask L1 Loss: 0.10795]
[D Loss: 0.99927] [G Loss: -0.06973] time_left: 14:30:50.573514
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 160, 160])
x1  torch.Size([32, 4, 160, 160])
finenet encoder  torch.Size([32, 192, 40, 40])
refine atten rs 1  torch.Size([32, 192, 40, 40])
after contextual attention  torch.Size([32, 192, 40, 40])
offset flow  torch.Size([32, 3, 160, 160])
refine atten rs 2 torch.Size([32, 192, 40, 40])
second out  torch.Size([32, 3, 160, 160])
final result  torch.Size([32, 3, 160, 160])
-----------------------------
[Epoch 2/2] [Batch 3/56358] [first Mask L1 Loss: 0.12676] [second Mask L1 Loss: 0.12462]
[D Loss: 0.99908] [G Loss: -0.07967] time_left: 14:26:36.900280
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 160, 160])
x1  torch.Size([32, 4, 160, 160])
finenet encoder  torch.Size([32, 192, 40, 40])
refine atten rs 1  torch.Size([32, 192, 40, 40])
after contextual attention  torch.Size([32, 192, 40, 40])
offset flow  torch.Size([32, 3, 160, 160])
refine atten rs 2 torch.Size([32, 192, 40, 40])
second out  torch.Size([32, 3, 160, 160])
final result  torch.Size([32, 3, 160, 160])
-----------------------------
[Epoch 2/2] [Batch 4/56358] [first Mask L1 Loss: 0.11335] [second Mask L1 Loss: 0.11343]
[D Loss: 1.00167] [G Loss: -0.07458] time_left: 14:52:07.314110
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 160, 160])
x1  torch.Size([32, 4, 160, 160])
finenet encoder  torch.Size([32, 192, 40, 40])
refine atten rs 1  torch.Size([32, 192, 40, 40])
after contextual attention  torch.Size([32, 192, 40, 40])
offset flow  torch.Size([32, 3, 160, 160])
refine atten rs 2 torch.Size([32, 192, 40, 40])
second out  torch.Size([32, 3, 160, 160])
final result  torch.Size([32, 3, 160, 160])
-----------------------------
[Epoch 2/2] [Batch 5/56358] [first Mask L1 Loss: 0.13304] [second Mask L1 Loss: 0.13191]
[D Loss: 0.99826] [G Loss: -0.06652] time_left: 14:29:38.585271
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 128, 190])
x1  torch.Size([32, 4, 128, 190])
finenet encoder  torch.Size([32, 192, 32, 48])
refine atten rs 1  torch.Size([32, 192, 32, 48])
after contextual attention  torch.Size([32, 192, 32, 48])
offset flow  torch.Size([32, 3, 128, 192])
refine atten rs 2 torch.Size([32, 192, 32, 48])
second out  torch.Size([32, 3, 128, 192])
final result  torch.Size([32, 3, 128, 190])
-----------------------------
[Epoch 2/2] [Batch 6/56358] [first Mask L1 Loss: 0.11329] [second Mask L1 Loss: 0.11002]
[D Loss: 0.99866] [G Loss: -0.07583] time_left: 2 days, 7:49:11.338623
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 128, 190])
x1  torch.Size([32, 4, 128, 190])
finenet encoder  torch.Size([32, 192, 32, 48])
refine atten rs 1  torch.Size([32, 192, 32, 48])
after contextual attention  torch.Size([32, 192, 32, 48])
offset flow  torch.Size([32, 3, 128, 192])
refine atten rs 2 torch.Size([32, 192, 32, 48])
second out  torch.Size([32, 3, 128, 192])
final result  torch.Size([32, 3, 128, 190])
-----------------------------
[Epoch 2/2] [Batch 7/56358] [first Mask L1 Loss: 0.08681] [second Mask L1 Loss: 0.08460]
[D Loss: 1.00353] [G Loss: -0.08687] time_left: 15:14:36.185985
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 128, 190])
x1  torch.Size([32, 4, 128, 190])
finenet encoder  torch.Size([32, 192, 32, 48])
refine atten rs 1  torch.Size([32, 192, 32, 48])
after contextual attention  torch.Size([32, 192, 32, 48])
offset flow  torch.Size([32, 3, 128, 192])
refine atten rs 2 torch.Size([32, 192, 32, 48])
second out  torch.Size([32, 3, 128, 192])
final result  torch.Size([32, 3, 128, 190])
-----------------------------
[Epoch 2/2] [Batch 8/56358] [first Mask L1 Loss: 0.10248] [second Mask L1 Loss: 0.09933]
[D Loss: 0.99727] [G Loss: -0.06309] time_left: 14:01:30.172541
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 128, 190])
x1  torch.Size([32, 4, 128, 190])
finenet encoder  torch.Size([32, 192, 32, 48])
refine atten rs 1  torch.Size([32, 192, 32, 48])
after contextual attention  torch.Size([32, 192, 32, 48])
offset flow  torch.Size([32, 3, 128, 192])
refine atten rs 2 torch.Size([32, 192, 32, 48])
second out  torch.Size([32, 3, 128, 192])
final result  torch.Size([32, 3, 128, 190])
-----------------------------
[Epoch 2/2] [Batch 9/56358] [first Mask L1 Loss: 0.10622] [second Mask L1 Loss: 0.10277]
[D Loss: 0.99724] [G Loss: -0.10665] time_left: 14:30:26.484061
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 128, 190])
x1  torch.Size([32, 4, 128, 190])
finenet encoder  torch.Size([32, 192, 32, 48])
refine atten rs 1  torch.Size([32, 192, 32, 48])
after contextual attention  torch.Size([32, 192, 32, 48])
offset flow  torch.Size([32, 3, 128, 192])
refine atten rs 2 torch.Size([32, 192, 32, 48])
second out  torch.Size([32, 3, 128, 192])
final result  torch.Size([32, 3, 128, 190])
-----------------------------
[Epoch 2/2] [Batch 10/56358] [first Mask L1 Loss: 0.10729] [second Mask L1 Loss: 0.10630]
[D Loss: 1.00480] [G Loss: -0.07861] time_left: 13:54:55.424026
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 128, 190])
x1  torch.Size([32, 4, 128, 190])
finenet encoder  torch.Size([32, 192, 32, 48])
refine atten rs 1  torch.Size([32, 192, 32, 48])
after contextual attention  torch.Size([32, 192, 32, 48])
offset flow  torch.Size([32, 3, 128, 192])
refine atten rs 2 torch.Size([32, 192, 32, 48])
second out  torch.Size([32, 3, 128, 192])
final result  torch.Size([32, 3, 128, 190])
-----------------------------
[Epoch 2/2] [Batch 11/56358] [first Mask L1 Loss: 0.09400] [second Mask L1 Loss: 0.08983]
[D Loss: 0.99796] [G Loss: -0.08461] time_left: 13:50:34.610636
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 160, 190])
x1  torch.Size([32, 4, 160, 190])
finenet encoder  torch.Size([32, 192, 40, 48])
refine atten rs 1  torch.Size([32, 192, 40, 48])
after contextual attention  torch.Size([32, 192, 40, 48])
offset flow  torch.Size([32, 3, 160, 192])
refine atten rs 2 torch.Size([32, 192, 40, 48])
second out  torch.Size([32, 3, 160, 192])
final result  torch.Size([32, 3, 160, 190])
-----------------------------
[Epoch 2/2] [Batch 12/56358] [first Mask L1 Loss: 0.09633] [second Mask L1 Loss: 0.09477]
[D Loss: 1.00147] [G Loss: -0.10447] time_left: 2 days, 18:18:07.718143
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 160, 190])
x1  torch.Size([32, 4, 160, 190])
finenet encoder  torch.Size([32, 192, 40, 48])
refine atten rs 1  torch.Size([32, 192, 40, 48])
after contextual attention  torch.Size([32, 192, 40, 48])
offset flow  torch.Size([32, 3, 160, 192])
refine atten rs 2 torch.Size([32, 192, 40, 48])
second out  torch.Size([32, 3, 160, 192])
final result  torch.Size([32, 3, 160, 190])
-----------------------------
[Epoch 2/2] [Batch 13/56358] [first Mask L1 Loss: 0.10015] [second Mask L1 Loss: 0.09776]
[D Loss: 0.99741] [G Loss: -0.08905] time_left: 18:19:02.515206
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 160, 190])
x1  torch.Size([32, 4, 160, 190])
finenet encoder  torch.Size([32, 192, 40, 48])
refine atten rs 1  torch.Size([32, 192, 40, 48])
after contextual attention  torch.Size([32, 192, 40, 48])
offset flow  torch.Size([32, 3, 160, 192])
refine atten rs 2 torch.Size([32, 192, 40, 48])
second out  torch.Size([32, 3, 160, 192])
final result  torch.Size([32, 3, 160, 190])
-----------------------------
[Epoch 2/2] [Batch 14/56358] [first Mask L1 Loss: 0.11483] [second Mask L1 Loss: 0.11413]
[D Loss: 1.00411] [G Loss: -0.10959] time_left: 16:54:57.887993
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 160, 190])
x1  torch.Size([32, 4, 160, 190])
finenet encoder  torch.Size([32, 192, 40, 48])
refine atten rs 1  torch.Size([32, 192, 40, 48])
after contextual attention  torch.Size([32, 192, 40, 48])
offset flow  torch.Size([32, 3, 160, 192])
refine atten rs 2 torch.Size([32, 192, 40, 48])
second out  torch.Size([32, 3, 160, 192])
final result  torch.Size([32, 3, 160, 190])
-----------------------------
[Epoch 2/2] [Batch 15/56358] [first Mask L1 Loss: 0.09908] [second Mask L1 Loss: 0.09668]
[D Loss: 0.99929] [G Loss: -0.09902] time_left: 17:31:28.127723
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 160, 190])
x1  torch.Size([32, 4, 160, 190])
finenet encoder  torch.Size([32, 192, 40, 48])
refine atten rs 1  torch.Size([32, 192, 40, 48])
after contextual attention  torch.Size([32, 192, 40, 48])
offset flow  torch.Size([32, 3, 160, 192])
refine atten rs 2 torch.Size([32, 192, 40, 48])
second out  torch.Size([32, 3, 160, 192])
final result  torch.Size([32, 3, 160, 190])
-----------------------------
[Epoch 2/2] [Batch 16/56358] [first Mask L1 Loss: 0.09373] [second Mask L1 Loss: 0.09173]
[D Loss: 1.00079] [G Loss: -0.09343] time_left: 16:52:47.105567
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 160, 190])
x1  torch.Size([32, 4, 160, 190])
finenet encoder  torch.Size([32, 192, 40, 48])
refine atten rs 1  torch.Size([32, 192, 40, 48])
after contextual attention  torch.Size([32, 192, 40, 48])
offset flow  torch.Size([32, 3, 160, 192])
refine atten rs 2 torch.Size([32, 192, 40, 48])
second out  torch.Size([32, 3, 160, 192])
final result  torch.Size([32, 3, 160, 190])
-----------------------------
[Epoch 2/2] [Batch 17/56358] [first Mask L1 Loss: 0.10763] [second Mask L1 Loss: 0.10585]
[D Loss: 1.00140] [G Loss: -0.09040] time_left: 17:10:51.768630
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 128, 230])
x1  torch.Size([32, 4, 128, 230])
finenet encoder  torch.Size([32, 192, 32, 58])
refine atten rs 1  torch.Size([32, 192, 32, 58])
after contextual attention  torch.Size([32, 192, 32, 58])
offset flow  torch.Size([32, 3, 128, 232])
refine atten rs 2 torch.Size([32, 192, 32, 58])
second out  torch.Size([32, 3, 128, 232])
final result  torch.Size([32, 3, 128, 230])
-----------------------------
[Epoch 2/2] [Batch 18/56358] [first Mask L1 Loss: 0.08200] [second Mask L1 Loss: 0.07743]
[D Loss: 0.99961] [G Loss: -0.08764] time_left: 2 days, 18:03:13.621545
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 128, 230])
x1  torch.Size([32, 4, 128, 230])
finenet encoder  torch.Size([32, 192, 32, 58])
refine atten rs 1  torch.Size([32, 192, 32, 58])
after contextual attention  torch.Size([32, 192, 32, 58])
offset flow  torch.Size([32, 3, 128, 232])
refine atten rs 2 torch.Size([32, 192, 32, 58])
second out  torch.Size([32, 3, 128, 232])
final result  torch.Size([32, 3, 128, 230])
-----------------------------
[Epoch 2/2] [Batch 19/56358] [first Mask L1 Loss: 0.08187] [second Mask L1 Loss: 0.07668]
[D Loss: 0.99962] [G Loss: -0.08320] time_left: 20:42:11.121515
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 128, 230])
x1  torch.Size([32, 4, 128, 230])
finenet encoder  torch.Size([32, 192, 32, 58])
refine atten rs 1  torch.Size([32, 192, 32, 58])
after contextual attention  torch.Size([32, 192, 32, 58])
offset flow  torch.Size([32, 3, 128, 232])
refine atten rs 2 torch.Size([32, 192, 32, 58])
second out  torch.Size([32, 3, 128, 232])
final result  torch.Size([32, 3, 128, 230])
-----------------------------
[Epoch 2/2] [Batch 20/56358] [first Mask L1 Loss: 0.08320] [second Mask L1 Loss: 0.07964]
[D Loss: 1.00159] [G Loss: -0.09784] time_left: 16:41:21.183252
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 128, 230])
x1  torch.Size([32, 4, 128, 230])
finenet encoder  torch.Size([32, 192, 32, 58])
refine atten rs 1  torch.Size([32, 192, 32, 58])
after contextual attention  torch.Size([32, 192, 32, 58])
offset flow  torch.Size([32, 3, 128, 232])
refine atten rs 2 torch.Size([32, 192, 32, 58])
second out  torch.Size([32, 3, 128, 232])
final result  torch.Size([32, 3, 128, 230])
-----------------------------
[Epoch 2/2] [Batch 21/56358] [first Mask L1 Loss: 0.08469] [second Mask L1 Loss: 0.07985]
[D Loss: 0.99898] [G Loss: -0.09228] time_left: 16:42:13.588757
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 128, 230])
x1  torch.Size([32, 4, 128, 230])
finenet encoder  torch.Size([32, 192, 32, 58])
refine atten rs 1  torch.Size([32, 192, 32, 58])
after contextual attention  torch.Size([32, 192, 32, 58])
offset flow  torch.Size([32, 3, 128, 232])
refine atten rs 2 torch.Size([32, 192, 32, 58])
second out  torch.Size([32, 3, 128, 232])
final result  torch.Size([32, 3, 128, 230])
-----------------------------
[Epoch 2/2] [Batch 22/56358] [first Mask L1 Loss: 0.07894] [second Mask L1 Loss: 0.07537]
[D Loss: 1.00075] [G Loss: -0.07788] time_left: 16:41:13.986675
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 128, 230])
x1  torch.Size([32, 4, 128, 230])
finenet encoder  torch.Size([32, 192, 32, 58])
refine atten rs 1  torch.Size([32, 192, 32, 58])
after contextual attention  torch.Size([32, 192, 32, 58])
offset flow  torch.Size([32, 3, 128, 232])
refine atten rs 2 torch.Size([32, 192, 32, 58])
second out  torch.Size([32, 3, 128, 232])
final result  torch.Size([32, 3, 128, 230])
-----------------------------
[Epoch 2/2] [Batch 23/56358] [first Mask L1 Loss: 0.07747] [second Mask L1 Loss: 0.07281]
[D Loss: 0.99833] [G Loss: -0.07705] time_left: 16:42:29.492226
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 230, 230])
x1  torch.Size([32, 4, 230, 230])
finenet encoder  torch.Size([32, 192, 58, 58])
refine atten rs 1  torch.Size([32, 192, 58, 58])
after contextual attention  torch.Size([32, 192, 58, 58])
offset flow  torch.Size([32, 3, 232, 232])
refine atten rs 2 torch.Size([32, 192, 58, 58])
second out  torch.Size([32, 3, 232, 232])
final result  torch.Size([32, 3, 230, 230])
-----------------------------
[Epoch 2/2] [Batch 24/56358] [first Mask L1 Loss: 0.07596] [second Mask L1 Loss: 0.07230]
[D Loss: 1.00038] [G Loss: -0.12659] time_left: 4 days, 7:51:38.325651
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 230, 230])
x1  torch.Size([32, 4, 230, 230])
finenet encoder  torch.Size([32, 192, 58, 58])
refine atten rs 1  torch.Size([32, 192, 58, 58])
after contextual attention  torch.Size([32, 192, 58, 58])
offset flow  torch.Size([32, 3, 232, 232])
refine atten rs 2 torch.Size([32, 192, 58, 58])
second out  torch.Size([32, 3, 232, 232])
final result  torch.Size([32, 3, 230, 230])
-----------------------------
[Epoch 2/2] [Batch 25/56358] [first Mask L1 Loss: 0.07861] [second Mask L1 Loss: 0.07682]
[D Loss: 1.00175] [G Loss: -0.11442] time_left: 1 day, 9:15:15.750654
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 230, 230])
x1  torch.Size([32, 4, 230, 230])
finenet encoder  torch.Size([32, 192, 58, 58])
refine atten rs 1  torch.Size([32, 192, 58, 58])
after contextual attention  torch.Size([32, 192, 58, 58])
offset flow  torch.Size([32, 3, 232, 232])
refine atten rs 2 torch.Size([32, 192, 58, 58])
second out  torch.Size([32, 3, 232, 232])
final result  torch.Size([32, 3, 230, 230])
-----------------------------
[Epoch 2/2] [Batch 26/56358] [first Mask L1 Loss: 0.07842] [second Mask L1 Loss: 0.07579]
[D Loss: 0.99752] [G Loss: -0.10979] time_left: 1 day, 4:54:59.577927
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 230, 230])
x1  torch.Size([32, 4, 230, 230])
finenet encoder  torch.Size([32, 192, 58, 58])
refine atten rs 1  torch.Size([32, 192, 58, 58])
after contextual attention  torch.Size([32, 192, 58, 58])
offset flow  torch.Size([32, 3, 232, 232])
refine atten rs 2 torch.Size([32, 192, 58, 58])
second out  torch.Size([32, 3, 232, 232])
final result  torch.Size([32, 3, 230, 230])
-----------------------------
[Epoch 2/2] [Batch 27/56358] [first Mask L1 Loss: 0.08658] [second Mask L1 Loss: 0.08384]
[D Loss: 0.99990] [G Loss: -0.12536] time_left: 1 day, 4:59:12.033771
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 230, 230])
x1  torch.Size([32, 4, 230, 230])
finenet encoder  torch.Size([32, 192, 58, 58])
refine atten rs 1  torch.Size([32, 192, 58, 58])
after contextual attention  torch.Size([32, 192, 58, 58])
offset flow  torch.Size([32, 3, 232, 232])
refine atten rs 2 torch.Size([32, 192, 58, 58])
second out  torch.Size([32, 3, 232, 232])
final result  torch.Size([32, 3, 230, 230])
-----------------------------
[Epoch 2/2] [Batch 28/56358] [first Mask L1 Loss: 0.07277] [second Mask L1 Loss: 0.06984]
[D Loss: 0.99968] [G Loss: -0.12350] time_left: 1 day, 5:03:03.704193
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 230, 230])
x1  torch.Size([32, 4, 230, 230])
finenet encoder  torch.Size([32, 192, 58, 58])
refine atten rs 1  torch.Size([32, 192, 58, 58])
after contextual attention  torch.Size([32, 192, 58, 58])
offset flow  torch.Size([32, 3, 232, 232])
refine atten rs 2 torch.Size([32, 192, 58, 58])
second out  torch.Size([32, 3, 232, 232])
final result  torch.Size([32, 3, 230, 230])
-----------------------------
[Epoch 2/2] [Batch 29/56358] [first Mask L1 Loss: 0.07745] [second Mask L1 Loss: 0.07466]
[D Loss: 1.00006] [G Loss: -0.11280] time_left: 1 day, 5:00:06.225025
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 128, 190])
x1  torch.Size([32, 4, 128, 190])
finenet encoder  torch.Size([32, 192, 32, 48])
refine atten rs 1  torch.Size([32, 192, 32, 48])
after contextual attention  torch.Size([32, 192, 32, 48])
offset flow  torch.Size([32, 3, 128, 192])
refine atten rs 2 torch.Size([32, 192, 32, 48])
second out  torch.Size([32, 3, 128, 192])
final result  torch.Size([32, 3, 128, 190])
-----------------------------
[Epoch 2/2] [Batch 30/56358] [first Mask L1 Loss: 0.10136] [second Mask L1 Loss: 0.09932]
[D Loss: 0.99978] [G Loss: -0.08185] time_left: 14:20:54.189228
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 128, 190])
x1  torch.Size([32, 4, 128, 190])
finenet encoder  torch.Size([32, 192, 32, 48])
refine atten rs 1  torch.Size([32, 192, 32, 48])
after contextual attention  torch.Size([32, 192, 32, 48])
offset flow  torch.Size([32, 3, 128, 192])
refine atten rs 2 torch.Size([32, 192, 32, 48])
second out  torch.Size([32, 3, 128, 192])
final result  torch.Size([32, 3, 128, 190])
-----------------------------
[Epoch 2/2] [Batch 31/56358] [first Mask L1 Loss: 0.11279] [second Mask L1 Loss: 0.10957]
[D Loss: 1.00074] [G Loss: -0.07669] time_left: 14:02:18.201988
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 128, 190])
x1  torch.Size([32, 4, 128, 190])
finenet encoder  torch.Size([32, 192, 32, 48])
refine atten rs 1  torch.Size([32, 192, 32, 48])
after contextual attention  torch.Size([32, 192, 32, 48])
offset flow  torch.Size([32, 3, 128, 192])
refine atten rs 2 torch.Size([32, 192, 32, 48])
second out  torch.Size([32, 3, 128, 192])
final result  torch.Size([32, 3, 128, 190])
-----------------------------
[Epoch 2/2] [Batch 32/56358] [first Mask L1 Loss: 0.11408] [second Mask L1 Loss: 0.11138]
[D Loss: 0.99720] [G Loss: -0.07770] time_left: 13:59:10.760230
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 128, 190])
x1  torch.Size([32, 4, 128, 190])
finenet encoder  torch.Size([32, 192, 32, 48])
refine atten rs 1  torch.Size([32, 192, 32, 48])
after contextual attention  torch.Size([32, 192, 32, 48])
offset flow  torch.Size([32, 3, 128, 192])
refine atten rs 2 torch.Size([32, 192, 32, 48])
second out  torch.Size([32, 3, 128, 192])
final result  torch.Size([32, 3, 128, 190])
-----------------------------
[Epoch 2/2] [Batch 33/56358] [first Mask L1 Loss: 0.11260] [second Mask L1 Loss: 0.11059]
[D Loss: 1.00269] [G Loss: -0.08357] time_left: 13:53:14.563776
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 128, 190])
x1  torch.Size([32, 4, 128, 190])
finenet encoder  torch.Size([32, 192, 32, 48])
refine atten rs 1  torch.Size([32, 192, 32, 48])
after contextual attention  torch.Size([32, 192, 32, 48])
offset flow  torch.Size([32, 3, 128, 192])
refine atten rs 2 torch.Size([32, 192, 32, 48])
second out  torch.Size([32, 3, 128, 192])
final result  torch.Size([32, 3, 128, 190])
-----------------------------
[Epoch 2/2] [Batch 34/56358] [first Mask L1 Loss: 0.10422] [second Mask L1 Loss: 0.10184]
[D Loss: 1.00079] [G Loss: -0.07030] time_left: 13:53:49.597908
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 128, 190])
x1  torch.Size([32, 4, 128, 190])
finenet encoder  torch.Size([32, 192, 32, 48])
refine atten rs 1  torch.Size([32, 192, 32, 48])
after contextual attention  torch.Size([32, 192, 32, 48])
offset flow  torch.Size([32, 3, 128, 192])
refine atten rs 2 torch.Size([32, 192, 32, 48])
second out  torch.Size([32, 3, 128, 192])
final result  torch.Size([32, 3, 128, 190])
-----------------------------
[Epoch 2/2] [Batch 35/56358] [first Mask L1 Loss: 0.09896] [second Mask L1 Loss: 0.09660]
[D Loss: 1.00137] [G Loss: -0.06343] time_left: 13:54:33.990394
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 190, 160])
x1  torch.Size([32, 4, 190, 160])
finenet encoder  torch.Size([32, 192, 48, 40])
refine atten rs 1  torch.Size([32, 192, 48, 40])
after contextual attention  torch.Size([32, 192, 48, 40])
offset flow  torch.Size([32, 3, 192, 160])
refine atten rs 2 torch.Size([32, 192, 48, 40])
second out  torch.Size([32, 3, 192, 160])
final result  torch.Size([32, 3, 190, 160])
-----------------------------
[Epoch 2/2] [Batch 36/56358] [first Mask L1 Loss: 0.09947] [second Mask L1 Loss: 0.09742]
[D Loss: 1.00178] [G Loss: -0.08286] time_left: 3 days, 5:14:18.385845
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 190, 160])
x1  torch.Size([32, 4, 190, 160])
finenet encoder  torch.Size([32, 192, 48, 40])
refine atten rs 1  torch.Size([32, 192, 48, 40])
after contextual attention  torch.Size([32, 192, 48, 40])
offset flow  torch.Size([32, 3, 192, 160])
refine atten rs 2 torch.Size([32, 192, 48, 40])
second out  torch.Size([32, 3, 192, 160])
final result  torch.Size([32, 3, 190, 160])
-----------------------------
[Epoch 2/2] [Batch 37/56358] [first Mask L1 Loss: 0.10375] [second Mask L1 Loss: 0.10119]
[D Loss: 0.99771] [G Loss: -0.08753] time_left: 17:44:04.303745
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 190, 160])
x1  torch.Size([32, 4, 190, 160])
finenet encoder  torch.Size([32, 192, 48, 40])
refine atten rs 1  torch.Size([32, 192, 48, 40])
after contextual attention  torch.Size([32, 192, 48, 40])
offset flow  torch.Size([32, 3, 192, 160])
refine atten rs 2 torch.Size([32, 192, 48, 40])
second out  torch.Size([32, 3, 192, 160])
final result  torch.Size([32, 3, 190, 160])
-----------------------------
[Epoch 2/2] [Batch 38/56358] [first Mask L1 Loss: 0.11020] [second Mask L1 Loss: 0.10838]
[D Loss: 1.00007] [G Loss: -0.07601] time_left: 16:55:57.294922
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 190, 160])
x1  torch.Size([32, 4, 190, 160])
finenet encoder  torch.Size([32, 192, 48, 40])
refine atten rs 1  torch.Size([32, 192, 48, 40])
after contextual attention  torch.Size([32, 192, 48, 40])
offset flow  torch.Size([32, 3, 192, 160])
refine atten rs 2 torch.Size([32, 192, 48, 40])
second out  torch.Size([32, 3, 192, 160])
final result  torch.Size([32, 3, 190, 160])
-----------------------------
[Epoch 2/2] [Batch 39/56358] [first Mask L1 Loss: 0.10750] [second Mask L1 Loss: 0.10538]
[D Loss: 1.00020] [G Loss: -0.07845] time_left: 16:54:44.375480
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 190, 160])
x1  torch.Size([32, 4, 190, 160])
finenet encoder  torch.Size([32, 192, 48, 40])
refine atten rs 1  torch.Size([32, 192, 48, 40])
after contextual attention  torch.Size([32, 192, 48, 40])
offset flow  torch.Size([32, 3, 192, 160])
refine atten rs 2 torch.Size([32, 192, 48, 40])
second out  torch.Size([32, 3, 192, 160])
final result  torch.Size([32, 3, 190, 160])
-----------------------------
[Epoch 2/2] [Batch 40/56358] [first Mask L1 Loss: 0.09988] [second Mask L1 Loss: 0.09928]
[D Loss: 1.00407] [G Loss: -0.07552] time_left: 22:46:18.133663
-----------------------------
-network each model rs shape-
x1 torch.Size([32, 3, 190, 160])
x1  torch.Size([32, 4, 190, 160])
finenet encoder  torch.Size([32, 192, 48, 40])
refine atten rs 1  torch.Size([32, 192, 48, 40])
after contextual attention  torch.Size([32, 192, 48, 40])
offset flow  torch.Size([32, 3, 192, 160])
refine atten rs 2 torch.Size([32, 192, 48, 40])
second out  torch.Size([32, 3, 192, 160])
final result  torch.Size([32, 3, 190, 160])